UPD ExpressionStatement@@MethodInvocation:executor.submit(new Runnable(){
  @Override public void run(){
    try {
      QueryPlan plan=hookContext.getQueryPlan();
      if (plan == null) {
        return;
      }
      String queryId=plan.getQueryId();
      String opId=hookContext.getOperationId();
      long queryStartTime=plan.getQueryStartTime();
      String user=hookContext.getUgi().getUserName();
      String requestuser=hookContext.getUserName();
      if (hookContext.getUserName() == null) {
        requestuser=hookContext.getUgi().getUserName();
      }
      int numMrJobs=Utilities.getMRTasks(plan.getRootTasks()).size();
      int numTezJobs=Utilities.getTezTasks(plan.getRootTasks()).size();
      if (numMrJobs + numTezJobs <= 0) {
        return;
      }
switch (hookContext.getHookType()) {
case PRE_EXEC_HOOK:
        ExplainConfiguration config=new ExplainConfiguration();
      config.setFormatted(true);
    ExplainWork work=new ExplainWork(null,null,plan.getRootTasks(),plan.getFetchTask(),null,config,null);
  @SuppressWarnings("unchecked") ExplainTask explain=(ExplainTask)TaskFactory.get(work,conf);
explain.initialize(queryState,plan,null,null);
String query=plan.getQueryStr();
JSONObject explainPlan=explain.getJSONPlan(null,work);
String logID=conf.getLogIdVar(hookContext.getSessionId());
List<String> tablesRead=getTablesFromEntitySet(hookContext.getInputs());
List<String> tablesWritten=getTablesFromEntitySet(hookContext.getOutputs());
String executionMode=getExecutionMode(plan).name();
String hiveInstanceAddress=hookContext.getHiveInstanceAddress();
if (hiveInstanceAddress == null) {
hiveInstanceAddress=InetAddress.getLocalHost().getHostAddress();
}
String hiveInstanceType=hookContext.isHiveServerQuery() ? "HS2" : "CLI";
fireAndForget(conf,createPreHookEvent(queryId,query,explainPlan,queryStartTime,user,requestuser,numMrJobs,numTezJobs,opId,hookContext.getIpAddress(),hiveInstanceAddress,hiveInstanceType,logID,hookContext.getThreadId(),executionMode,tablesRead,tablesWritten,conf));
break;
case POST_EXEC_HOOK:
fireAndForget(conf,createPostHookEvent(queryId,currentTime,user,requestuser,true,opId,hookContext.getPerfLogger()));
break;
case ON_FAILURE_HOOK:
fireAndForget(conf,createPostHookEvent(queryId,currentTime,user,requestuser,false,opId,hookContext.getPerfLogger()));
break;
default :
break;
}
}
 catch (Exception e) {
LOG.info("Failed to submit plan to ATS: " + StringUtils.stringifyException(e));
}
}
}
) @TO@ MethodInvocation:executor.submit(new Runnable(){
  @Override public void run(){
    try {
      QueryPlan plan=hookContext.getQueryPlan();
      if (plan == null) {
        return;
      }
      String queryId=plan.getQueryId();
      String opId=hookContext.getOperationId();
      long queryStartTime=plan.getQueryStartTime();
      String user=hookContext.getUgi().getUserName();
      String requestuser=hookContext.getUserName();
      if (hookContext.getUserName() == null) {
        requestuser=hookContext.getUgi().getUserName();
      }
      int numMrJobs=Utilities.getMRTasks(plan.getRootTasks()).size();
      int numTezJobs=Utilities.getTezTasks(plan.getRootTasks()).size();
      if (numMrJobs + numTezJobs <= 0) {
        return;
      }
switch (hookContext.getHookType()) {
case PRE_EXEC_HOOK:
        ExplainConfiguration config=new ExplainConfiguration();
      config.setFormatted(true);
    ExplainWork work=new ExplainWork(null,null,plan.getRootTasks(),plan.getFetchTask(),null,config,null);
  @SuppressWarnings("unchecked") ExplainTask explain=(ExplainTask)TaskFactory.get(work,conf);
explain.initialize(queryState,plan,null,null);
String query=plan.getQueryStr();
JSONObject explainPlan=explain.getJSONPlan(null,work);
String logID=conf.getLogIdVar(hookContext.getSessionId());
List<String> tablesRead=getTablesFromEntitySet(hookContext.getInputs());
List<String> tablesWritten=getTablesFromEntitySet(hookContext.getOutputs());
String executionMode=getExecutionMode(plan).name();
String hiveInstanceAddress=hookContext.getHiveInstanceAddress();
if (hiveInstanceAddress == null) {
hiveInstanceAddress=InetAddress.getLocalHost().getHostAddress();
}
String hiveInstanceType=hookContext.isHiveServerQuery() ? "HS2" : "CLI";
fireAndForget(conf,createPreHookEvent(queryId,query,explainPlan,queryStartTime,user,requestuser,numMrJobs,numTezJobs,opId,hookContext.getIpAddress(),hiveInstanceAddress,hiveInstanceType,hookContext.getSessionId(),logID,hookContext.getThreadId(),executionMode,tablesRead,tablesWritten,conf));
break;
case POST_EXEC_HOOK:
fireAndForget(conf,createPostHookEvent(queryId,currentTime,user,requestuser,true,opId,hookContext.getPerfLogger()));
break;
case ON_FAILURE_HOOK:
fireAndForget(conf,createPostHookEvent(queryId,currentTime,user,requestuser,false,opId,hookContext.getPerfLogger()));
break;
default :
break;
}
}
 catch (Exception e) {
LOG.info("Failed to submit plan to ATS: " + StringUtils.stringifyException(e));
}
}
}
) @AT@ 4593 @LENGTH@ 3407
---UPD MethodInvocation@@executor.submit(new Runnable(){
  @Override public void run(){
    try {
      QueryPlan plan=hookContext.getQueryPlan();
      if (plan == null) {
        return;
      }
      String queryId=plan.getQueryId();
      String opId=hookContext.getOperationId();
      long queryStartTime=plan.getQueryStartTime();
      String user=hookContext.getUgi().getUserName();
      String requestuser=hookContext.getUserName();
      if (hookContext.getUserName() == null) {
        requestuser=hookContext.getUgi().getUserName();
      }
      int numMrJobs=Utilities.getMRTasks(plan.getRootTasks()).size();
      int numTezJobs=Utilities.getTezTasks(plan.getRootTasks()).size();
      if (numMrJobs + numTezJobs <= 0) {
        return;
      }
switch (hookContext.getHookType()) {
case PRE_EXEC_HOOK:
        ExplainConfiguration config=new ExplainConfiguration();
      config.setFormatted(true);
    ExplainWork work=new ExplainWork(null,null,plan.getRootTasks(),plan.getFetchTask(),null,config,null);
  @SuppressWarnings("unchecked") ExplainTask explain=(ExplainTask)TaskFactory.get(work,conf);
explain.initialize(queryState,plan,null,null);
String query=plan.getQueryStr();
JSONObject explainPlan=explain.getJSONPlan(null,work);
String logID=conf.getLogIdVar(hookContext.getSessionId());
List<String> tablesRead=getTablesFromEntitySet(hookContext.getInputs());
List<String> tablesWritten=getTablesFromEntitySet(hookContext.getOutputs());
String executionMode=getExecutionMode(plan).name();
String hiveInstanceAddress=hookContext.getHiveInstanceAddress();
if (hiveInstanceAddress == null) {
hiveInstanceAddress=InetAddress.getLocalHost().getHostAddress();
}
String hiveInstanceType=hookContext.isHiveServerQuery() ? "HS2" : "CLI";
fireAndForget(conf,createPreHookEvent(queryId,query,explainPlan,queryStartTime,user,requestuser,numMrJobs,numTezJobs,opId,hookContext.getIpAddress(),hiveInstanceAddress,hiveInstanceType,logID,hookContext.getThreadId(),executionMode,tablesRead,tablesWritten,conf));
break;
case POST_EXEC_HOOK:
fireAndForget(conf,createPostHookEvent(queryId,currentTime,user,requestuser,true,opId,hookContext.getPerfLogger()));
break;
case ON_FAILURE_HOOK:
fireAndForget(conf,createPostHookEvent(queryId,currentTime,user,requestuser,false,opId,hookContext.getPerfLogger()));
break;
default :
break;
}
}
 catch (Exception e) {
LOG.info("Failed to submit plan to ATS: " + StringUtils.stringifyException(e));
}
}
}
) @TO@ executor.submit(new Runnable(){
  @Override public void run(){
    try {
      QueryPlan plan=hookContext.getQueryPlan();
      if (plan == null) {
        return;
      }
      String queryId=plan.getQueryId();
      String opId=hookContext.getOperationId();
      long queryStartTime=plan.getQueryStartTime();
      String user=hookContext.getUgi().getUserName();
      String requestuser=hookContext.getUserName();
      if (hookContext.getUserName() == null) {
        requestuser=hookContext.getUgi().getUserName();
      }
      int numMrJobs=Utilities.getMRTasks(plan.getRootTasks()).size();
      int numTezJobs=Utilities.getTezTasks(plan.getRootTasks()).size();
      if (numMrJobs + numTezJobs <= 0) {
        return;
      }
switch (hookContext.getHookType()) {
case PRE_EXEC_HOOK:
        ExplainConfiguration config=new ExplainConfiguration();
      config.setFormatted(true);
    ExplainWork work=new ExplainWork(null,null,plan.getRootTasks(),plan.getFetchTask(),null,config,null);
  @SuppressWarnings("unchecked") ExplainTask explain=(ExplainTask)TaskFactory.get(work,conf);
explain.initialize(queryState,plan,null,null);
String query=plan.getQueryStr();
JSONObject explainPlan=explain.getJSONPlan(null,work);
String logID=conf.getLogIdVar(hookContext.getSessionId());
List<String> tablesRead=getTablesFromEntitySet(hookContext.getInputs());
List<String> tablesWritten=getTablesFromEntitySet(hookContext.getOutputs());
String executionMode=getExecutionMode(plan).name();
String hiveInstanceAddress=hookContext.getHiveInstanceAddress();
if (hiveInstanceAddress == null) {
hiveInstanceAddress=InetAddress.getLocalHost().getHostAddress();
}
String hiveInstanceType=hookContext.isHiveServerQuery() ? "HS2" : "CLI";
fireAndForget(conf,createPreHookEvent(queryId,query,explainPlan,queryStartTime,user,requestuser,numMrJobs,numTezJobs,opId,hookContext.getIpAddress(),hiveInstanceAddress,hiveInstanceType,hookContext.getSessionId(),logID,hookContext.getThreadId(),executionMode,tablesRead,tablesWritten,conf));
break;
case POST_EXEC_HOOK:
fireAndForget(conf,createPostHookEvent(queryId,currentTime,user,requestuser,true,opId,hookContext.getPerfLogger()));
break;
case ON_FAILURE_HOOK:
fireAndForget(conf,createPostHookEvent(queryId,currentTime,user,requestuser,false,opId,hookContext.getPerfLogger()));
break;
default :
break;
}
}
 catch (Exception e) {
LOG.info("Failed to submit plan to ATS: " + StringUtils.stringifyException(e));
}
}
}
) @AT@ 4593 @LENGTH@ 3406
------UPD SimpleName@@MethodName:submit:[new Runnable(){
  @Override public void run(){
    try {
      QueryPlan plan=hookContext.getQueryPlan();
      if (plan == null) {
        return;
      }
      String queryId=plan.getQueryId();
      String opId=hookContext.getOperationId();
      long queryStartTime=plan.getQueryStartTime();
      String user=hookContext.getUgi().getUserName();
      String requestuser=hookContext.getUserName();
      if (hookContext.getUserName() == null) {
        requestuser=hookContext.getUgi().getUserName();
      }
      int numMrJobs=Utilities.getMRTasks(plan.getRootTasks()).size();
      int numTezJobs=Utilities.getTezTasks(plan.getRootTasks()).size();
      if (numMrJobs + numTezJobs <= 0) {
        return;
      }
switch (hookContext.getHookType()) {
case PRE_EXEC_HOOK:
        ExplainConfiguration config=new ExplainConfiguration();
      config.setFormatted(true);
    ExplainWork work=new ExplainWork(null,null,plan.getRootTasks(),plan.getFetchTask(),null,config,null);
  @SuppressWarnings("unchecked") ExplainTask explain=(ExplainTask)TaskFactory.get(work,conf);
explain.initialize(queryState,plan,null,null);
String query=plan.getQueryStr();
JSONObject explainPlan=explain.getJSONPlan(null,work);
String logID=conf.getLogIdVar(hookContext.getSessionId());
List<String> tablesRead=getTablesFromEntitySet(hookContext.getInputs());
List<String> tablesWritten=getTablesFromEntitySet(hookContext.getOutputs());
String executionMode=getExecutionMode(plan).name();
String hiveInstanceAddress=hookContext.getHiveInstanceAddress();
if (hiveInstanceAddress == null) {
hiveInstanceAddress=InetAddress.getLocalHost().getHostAddress();
}
String hiveInstanceType=hookContext.isHiveServerQuery() ? "HS2" : "CLI";
fireAndForget(conf,createPreHookEvent(queryId,query,explainPlan,queryStartTime,user,requestuser,numMrJobs,numTezJobs,opId,hookContext.getIpAddress(),hiveInstanceAddress,hiveInstanceType,logID,hookContext.getThreadId(),executionMode,tablesRead,tablesWritten,conf));
break;
case POST_EXEC_HOOK:
fireAndForget(conf,createPostHookEvent(queryId,currentTime,user,requestuser,true,opId,hookContext.getPerfLogger()));
break;
case ON_FAILURE_HOOK:
fireAndForget(conf,createPostHookEvent(queryId,currentTime,user,requestuser,false,opId,hookContext.getPerfLogger()));
break;
default :
break;
}
}
 catch (Exception e) {
LOG.info("Failed to submit plan to ATS: " + StringUtils.stringifyException(e));
}
}
}
] @TO@ MethodName:submit:[new Runnable(){
  @Override public void run(){
    try {
      QueryPlan plan=hookContext.getQueryPlan();
      if (plan == null) {
        return;
      }
      String queryId=plan.getQueryId();
      String opId=hookContext.getOperationId();
      long queryStartTime=plan.getQueryStartTime();
      String user=hookContext.getUgi().getUserName();
      String requestuser=hookContext.getUserName();
      if (hookContext.getUserName() == null) {
        requestuser=hookContext.getUgi().getUserName();
      }
      int numMrJobs=Utilities.getMRTasks(plan.getRootTasks()).size();
      int numTezJobs=Utilities.getTezTasks(plan.getRootTasks()).size();
      if (numMrJobs + numTezJobs <= 0) {
        return;
      }
switch (hookContext.getHookType()) {
case PRE_EXEC_HOOK:
        ExplainConfiguration config=new ExplainConfiguration();
      config.setFormatted(true);
    ExplainWork work=new ExplainWork(null,null,plan.getRootTasks(),plan.getFetchTask(),null,config,null);
  @SuppressWarnings("unchecked") ExplainTask explain=(ExplainTask)TaskFactory.get(work,conf);
explain.initialize(queryState,plan,null,null);
String query=plan.getQueryStr();
JSONObject explainPlan=explain.getJSONPlan(null,work);
String logID=conf.getLogIdVar(hookContext.getSessionId());
List<String> tablesRead=getTablesFromEntitySet(hookContext.getInputs());
List<String> tablesWritten=getTablesFromEntitySet(hookContext.getOutputs());
String executionMode=getExecutionMode(plan).name();
String hiveInstanceAddress=hookContext.getHiveInstanceAddress();
if (hiveInstanceAddress == null) {
hiveInstanceAddress=InetAddress.getLocalHost().getHostAddress();
}
String hiveInstanceType=hookContext.isHiveServerQuery() ? "HS2" : "CLI";
fireAndForget(conf,createPreHookEvent(queryId,query,explainPlan,queryStartTime,user,requestuser,numMrJobs,numTezJobs,opId,hookContext.getIpAddress(),hiveInstanceAddress,hiveInstanceType,hookContext.getSessionId(),logID,hookContext.getThreadId(),executionMode,tablesRead,tablesWritten,conf));
break;
case POST_EXEC_HOOK:
fireAndForget(conf,createPostHookEvent(queryId,currentTime,user,requestuser,true,opId,hookContext.getPerfLogger()));
break;
case ON_FAILURE_HOOK:
fireAndForget(conf,createPostHookEvent(queryId,currentTime,user,requestuser,false,opId,hookContext.getPerfLogger()));
break;
default :
break;
}
}
 catch (Exception e) {
LOG.info("Failed to submit plan to ATS: " + StringUtils.stringifyException(e));
}
}
}
] @AT@ 4602 @LENGTH@ 3397

